{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, Embedding, Dense, Input, LSTM, TextVectorization\n",
    "from tensorflow.keras.models import load_model\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2e6ae-39c0-4140-aaba-6005a91efe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sz = 1000\n",
    "seq_len = 100\n",
    "embed_out_dim = 64\n",
    "\n",
    "bidirectional = False\n",
    "lstm_layer = 1\n",
    "    \n",
    "# One value: Applies to all LSTM layers\n",
    "# List of values: Specific to each LSTM layer\n",
    "lstm_out_dim = 64\n",
    "lstm_bias = True\n",
    "# Supported activations: tanh, sigmoid, relu, None\n",
    "lstm_activation = 'tanh'\n",
    "lstm_rec_activation = 'sigmoid'\n",
    "\n",
    "fc_layer = 2\n",
    "fc_out_dim = [64, 2]\n",
    "fc_activation = ['relu', 'softmax']\n",
    "fc_bias = True\n",
    "\n",
    "optimiser = 'adam'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "metrics = ['acc']\n",
    "\n",
    "batch_sz = 64\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fe533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    model = Sequential([Input(seq_len),\n",
    "                        Embedding(vocab_sz, embed_out_dim)])\n",
    "    \n",
    "    for index in range(lstm_layer):\n",
    "        lstm = LSTM(lstm_out_dim[index] if type(lstm_out_dim) == list else lstm_out_dim,\n",
    "                    lstm_activation[index] if type(lstm_activation) == list else lstm_activation,\n",
    "                    lstm_rec_activation[index] if type(lstm_rec_activation) == list else lstm_rec_activation,\n",
    "                    lstm_bias[index] if type(lstm_bias) == list else lstm_bias,\n",
    "                    return_sequences = index != lstm_layer - 1)\n",
    "        \n",
    "        model.add(Bidirectional(lstm) if bidirectional else lstm)\n",
    "\n",
    "    for index in range(fc_layer):\n",
    "        model.add(Dense(fc_out_dim[index] if type(fc_out_dim) == list else fc_out_dim,\n",
    "                        fc_activation[index] if type(fc_activation) == list else fc_activation,\n",
    "                        fc_bias[index] if type(fc_bias) == list else fc_bias))\n",
    "\n",
    "    model.compile(optimiser, loss, metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1deec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('train_data.txt') or not os.path.exists('train_label.txt') or not os.path.exists('test_data.txt') or not os.path.exists('test_label.txt'):\n",
    "    dataset = tfds.load('imdb_reviews', as_supervised = True)\n",
    "    train_data = dataset['train'].shuffle(buffer_sz)\n",
    "    test_data = dataset['test'].shuffle(buffer_sz)\n",
    "    \n",
    "    encoder = TextVectorization(vocab_sz, output_sequence_length = seq_len)\n",
    "    encoder.adapt(train_data.map(lambda text, label: text))\n",
    "    \n",
    "    data_file = open('train_data.txt', 'w')\n",
    "    label_file = open('train_label.txt', 'w')\n",
    "\n",
    "    for vector, label in train_data:\n",
    "        data_file.write(str(encoder(vector).numpy().tolist()) + '\\n')\n",
    "        label_file.write(str(label.numpy()) + '\\n')\n",
    "\n",
    "    data_file.close()\n",
    "    label_file.close()\n",
    "    \n",
    "    data_file = open('test_data.txt', 'w')\n",
    "    label_file = open('test_label.txt', 'w')\n",
    "\n",
    "    for vector, label in test_data:\n",
    "        data_file.write(str(encoder(vector).numpy().tolist()) + '\\n')\n",
    "        label_file.write(str(label.numpy()) + '\\n')\n",
    "\n",
    "    data_file.close()\n",
    "    label_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f81daf-79ac-4c48-9306-9ca47e9bb2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open('train_data.txt', 'r')\n",
    "label_file = open('train_label.txt', 'r')\n",
    "\n",
    "vectors = data_file.readlines()\n",
    "labels = label_file.readlines()\n",
    "\n",
    "train_data = np.zeros((len(vectors), seq_len), np.int64)\n",
    "train_label = np.zeros(len(labels), np.int64)\n",
    "\n",
    "for index, vector in enumerate(vectors):\n",
    "    train_data[index] = eval(vector)\n",
    "    train_label[index] = labels[index]\n",
    "\n",
    "data_file.close()\n",
    "label_file.close()\n",
    "\n",
    "data_file = open('test_data.txt', 'r')\n",
    "label_file = open('test_label.txt', 'r')\n",
    "\n",
    "vectors = data_file.readlines()\n",
    "labels = label_file.readlines()\n",
    "\n",
    "test_data = np.zeros((len(vectors), seq_len), np.int64)\n",
    "test_label = np.zeros(len(labels), np.int64)\n",
    "\n",
    "for index, vector in enumerate(vectors):\n",
    "    test_data[index] = eval(vector)\n",
    "    test_label[index] = labels[index]\n",
    "\n",
    "data_file.close()\n",
    "label_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc031c-64df-4f12-a29b-006dff6b6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('lstm.h5'):\n",
    "    model = lstm_model()\n",
    "else:\n",
    "    model = load_model('lstm.h5')\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fdb81-6830-4c4d-ad93-c3d7e71ff538",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('lstm.h5'):\n",
    "    history = model.fit(train_data, train_label, batch_sz, num_epoch, validation_split = 0.3)\n",
    "    model.save('lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b5476-542a-493f-981f-2d1ffb183b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e17df0-0acb-4ea4-a720-d8cf693f06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8abf0-3b14-4f78-af44-d3520bbd7dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
